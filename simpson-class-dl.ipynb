{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063022c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T16:58:41.952536Z",
     "iopub.status.busy": "2023-08-16T16:58:41.950778Z",
     "iopub.status.idle": "2023-08-16T16:58:42.228755Z",
     "shell.execute_reply": "2023-08-16T16:58:42.227302Z"
    },
    "papermill": {
     "duration": 0.383982,
     "end_time": "2023-08-16T16:58:42.232141",
     "exception": false,
     "start_time": "2023-08-16T16:58:41.848159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cccc691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T16:58:42.440881Z",
     "iopub.status.busy": "2023-08-16T16:58:42.439967Z",
     "iopub.status.idle": "2023-08-16T16:58:42.447412Z",
     "shell.execute_reply": "2023-08-16T16:58:42.445974Z"
    },
    "papermill": {
     "duration": 0.116349,
     "end_time": "2023-08-16T16:58:42.450352",
     "exception": false,
     "start_time": "2023-08-16T16:58:42.334003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson', \n",
    "        3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n",
    "        7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson', \n",
    "        11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak', \n",
    "        14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8e89db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T16:58:42.671377Z",
     "iopub.status.busy": "2023-08-16T16:58:42.670719Z",
     "iopub.status.idle": "2023-08-16T16:58:42.680155Z",
     "shell.execute_reply": "2023-08-16T16:58:42.679292Z"
    },
    "papermill": {
     "duration": 0.122036,
     "end_time": "2023-08-16T16:58:42.682753",
     "exception": false,
     "start_time": "2023-08-16T16:58:42.560717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(img_size):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for num, chars in map_characters.items(): \n",
    "        path = f'/kaggle/input/the-simpsons-characters-dataset/simpsons_dataset/{chars}/*.jpg'\n",
    "        image_paths = glob.glob(path)\n",
    "        for path in image_paths:\n",
    "            image = cv2.imread(path)  # Reads the image in BGR format\n",
    "            image = cv2.resize(image, img_size, interpolation=cv2.INTER_AREA).astype('float32') / 255 # Converts it to uniform size and scales it down\n",
    "            X_data.append(image)\n",
    "            y_data.append(num)\n",
    "        print(chars)\n",
    "    \n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "            \n",
    "    return X_data, y_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76897c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T16:58:42.905369Z",
     "iopub.status.busy": "2023-08-16T16:58:42.904742Z",
     "iopub.status.idle": "2023-08-16T17:03:17.763621Z",
     "shell.execute_reply": "2023-08-16T17:03:17.762057Z"
    },
    "papermill": {
     "duration": 274.970325,
     "end_time": "2023-08-16T17:03:17.766964",
     "exception": false,
     "start_time": "2023-08-16T16:58:42.796639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abraham_grampa_simpson\n",
      "apu_nahasapeemapetilon\n",
      "bart_simpson\n",
      "charles_montgomery_burns\n",
      "chief_wiggum\n",
      "comic_book_guy\n",
      "edna_krabappel\n",
      "homer_simpson\n",
      "kent_brockman\n",
      "krusty_the_clown\n",
      "lisa_simpson\n",
      "marge_simpson\n",
      "milhouse_van_houten\n",
      "moe_szyslak\n",
      "ned_flanders\n",
      "nelson_muntz\n",
      "principal_skinner\n",
      "sideshow_bob\n"
     ]
    }
   ],
   "source": [
    "img_size = (200,200)\n",
    "X_data, y_data = load_data(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff80fdbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:03:17.987839Z",
     "iopub.status.busy": "2023-08-16T17:03:17.987260Z",
     "iopub.status.idle": "2023-08-16T17:03:52.364963Z",
     "shell.execute_reply": "2023-08-16T17:03:52.361547Z"
    },
    "papermill": {
     "duration": 34.498603,
     "end_time": "2023-08-16T17:03:52.373614",
     "exception": false,
     "start_time": "2023-08-16T17:03:17.875011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('/kaggle/working/X.npy', X_data)\n",
    "np.save('/kaggle/working/y.npy', y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4daa926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:03:52.695607Z",
     "iopub.status.busy": "2023-08-16T17:03:52.694662Z",
     "iopub.status.idle": "2023-08-16T17:03:52.702747Z",
     "shell.execute_reply": "2023-08-16T17:03:52.701616Z"
    },
    "papermill": {
     "duration": 0.146981,
     "end_time": "2023-08-16T17:03:52.705687",
     "exception": false,
     "start_time": "2023-08-16T17:03:52.558706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False: \n",
    "    X_data = np.load('/kaggle/working/X.npy')\n",
    "    y_data = np.load('/kaggle/working/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87ea9cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:03:52.988642Z",
     "iopub.status.busy": "2023-08-16T17:03:52.987263Z",
     "iopub.status.idle": "2023-08-16T17:04:06.904843Z",
     "shell.execute_reply": "2023-08-16T17:04:06.902866Z"
    },
    "papermill": {
     "duration": 14.042784,
     "end_time": "2023-08-16T17:04:06.908357",
     "exception": false,
     "start_time": "2023-08-16T17:03:52.865573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in train set: {0: 730, 1: 498, 2: 1074, 3: 954, 4: 789, 5: 375, 6: 366, 7: 1797, 8: 398, 9: 965, 10: 1083, 11: 1033, 12: 863, 13: 1162, 14: 1163, 15: 286, 16: 955, 17: 702}\n",
      "Class distribution in test set: {0: 183, 1: 125, 2: 268, 3: 239, 4: 197, 5: 94, 6: 91, 7: 449, 8: 100, 9: 241, 10: 271, 11: 258, 12: 216, 13: 290, 14: 291, 15: 72, 16: 239, 17: 175}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, stratify=y_data, random_state=42)\n",
    "\n",
    "# Print the class distribution proportions in the train set\n",
    "unique_classes, class_counts_train = np.unique(y_train, return_counts=True)\n",
    "class_distribution_train = dict(zip(unique_classes, class_counts_train))\n",
    "print(\"Class distribution in train set:\", class_distribution_train)\n",
    "\n",
    "# Print the class distribution proportions in the test set\n",
    "unique_classes, class_counts_test = np.unique(y_test, return_counts=True)\n",
    "class_distribution_test = dict(zip(unique_classes, class_counts_test))\n",
    "print(\"Class distribution in test set:\", class_distribution_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baac0aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:07.148300Z",
     "iopub.status.busy": "2023-08-16T17:04:07.147258Z",
     "iopub.status.idle": "2023-08-16T17:04:12.096049Z",
     "shell.execute_reply": "2023-08-16T17:04:12.094279Z"
    },
    "papermill": {
     "duration": 5.056664,
     "end_time": "2023-08-16T17:04:12.099400",
     "exception": false,
     "start_time": "2023-08-16T17:04:07.042736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec18221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:12.359443Z",
     "iopub.status.busy": "2023-08-16T17:04:12.358479Z",
     "iopub.status.idle": "2023-08-16T17:04:16.630889Z",
     "shell.execute_reply": "2023-08-16T17:04:16.629486Z"
    },
    "papermill": {
     "duration": 4.382036,
     "end_time": "2023-08-16T17:04:16.634118",
     "exception": false,
     "start_time": "2023-08-16T17:04:12.252082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "dev_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705ac0b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:16.844396Z",
     "iopub.status.busy": "2023-08-16T17:04:16.843935Z",
     "iopub.status.idle": "2023-08-16T17:04:16.849768Z",
     "shell.execute_reply": "2023-08-16T17:04:16.848799Z"
    },
    "papermill": {
     "duration": 0.112551,
     "end_time": "2023-08-16T17:04:16.852177",
     "exception": false,
     "start_time": "2023-08-16T17:04:16.739626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "hidden_size = 256\n",
    "num_classes = 18\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bf9daf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:17.264115Z",
     "iopub.status.busy": "2023-08-16T17:04:17.263196Z",
     "iopub.status.idle": "2023-08-16T17:04:17.291443Z",
     "shell.execute_reply": "2023-08-16T17:04:17.290373Z"
    },
    "papermill": {
     "duration": 0.133474,
     "end_time": "2023-08-16T17:04:17.294391",
     "exception": false,
     "start_time": "2023-08-16T17:04:17.160917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    del X_data, y_data\n",
    "    del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "099b8ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:17.497202Z",
     "iopub.status.busy": "2023-08-16T17:04:17.496751Z",
     "iopub.status.idle": "2023-08-16T17:04:17.859506Z",
     "shell.execute_reply": "2023-08-16T17:04:17.856953Z"
    },
    "papermill": {
     "duration": 0.467888,
     "end_time": "2023-08-16T17:04:17.863177",
     "exception": false,
     "start_time": "2023-08-16T17:04:17.395289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=120000, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(200*200*3, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net(hidden_size, num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3764f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:18.081350Z",
     "iopub.status.busy": "2023-08-16T17:04:18.080820Z",
     "iopub.status.idle": "2023-08-16T17:04:18.087383Z",
     "shell.execute_reply": "2023-08-16T17:04:18.085976Z"
    },
    "papermill": {
     "duration": 0.119158,
     "end_time": "2023-08-16T17:04:18.089949",
     "exception": false,
     "start_time": "2023-08-16T17:04:17.970791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fce96ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:18.304621Z",
     "iopub.status.busy": "2023-08-16T17:04:18.303585Z",
     "iopub.status.idle": "2023-08-16T17:04:18.317685Z",
     "shell.execute_reply": "2023-08-16T17:04:18.316621Z"
    },
    "papermill": {
     "duration": 0.126538,
     "end_time": "2023-08-16T17:04:18.320688",
     "exception": false,
     "start_time": "2023-08-16T17:04:18.194150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dev_dataloader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images.view(-1,200*200*3))\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_dataloader, 0):\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images.view(-1,200*200*3))\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_function(outputs, labels)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "#         # we want to save the model if the accuracy is the best\n",
    "#         if accuracy > best_accuracy:\n",
    "#             saveModel()\n",
    "#             best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e321c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:45:20.044562Z",
     "iopub.status.busy": "2023-08-16T12:45:20.044098Z",
     "iopub.status.idle": "2023-08-16T12:50:12.077198Z",
     "shell.execute_reply": "2023-08-16T12:50:12.075190Z",
     "shell.execute_reply.started": "2023-08-16T12:45:20.044528Z"
    },
    "papermill": {
     "duration": 0.10387,
     "end_time": "2023-08-16T17:04:18.529446",
     "exception": false,
     "start_time": "2023-08-16T17:04:18.425576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a371ea",
   "metadata": {
    "papermill": {
     "duration": 0.105746,
     "end_time": "2023-08-16T17:04:18.741344",
     "exception": false,
     "start_time": "2023-08-16T17:04:18.635598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19717027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:18.957704Z",
     "iopub.status.busy": "2023-08-16T17:04:18.957208Z",
     "iopub.status.idle": "2023-08-16T17:04:18.969955Z",
     "shell.execute_reply": "2023-08-16T17:04:18.968855Z"
    },
    "papermill": {
     "duration": 0.122848,
     "end_time": "2023-08-16T17:04:18.972564",
     "exception": false,
     "start_time": "2023-08-16T17:04:18.849716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.view(-1, 3*200*200))                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.view(-1, 3*200*200))                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(f\"Epoch {epoch}, train_loss: {result['train_loss']:.4f}, val_loss: {result['val_loss']:.4f}, val_acc: {result['val_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "373da4c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:19.192148Z",
     "iopub.status.busy": "2023-08-16T17:04:19.191105Z",
     "iopub.status.idle": "2023-08-16T17:04:19.202967Z",
     "shell.execute_reply": "2023-08-16T17:04:19.201872Z"
    },
    "papermill": {
     "duration": 0.124305,
     "end_time": "2023-08-16T17:04:19.205944",
     "exception": false,
     "start_time": "2023-08-16T17:04:19.081639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpsonClassifier(ImageClassificationBase):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(625,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caf69d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:19.642481Z",
     "iopub.status.busy": "2023-08-16T17:04:19.641185Z",
     "iopub.status.idle": "2023-08-16T17:04:19.652731Z",
     "shell.execute_reply": "2023-08-16T17:04:19.651618Z"
    },
    "papermill": {
     "duration": 0.122181,
     "end_time": "2023-08-16T17:04:19.655521",
     "exception": false,
     "start_time": "2023-08-16T17:04:19.533340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f2b132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:19.858465Z",
     "iopub.status.busy": "2023-08-16T17:04:19.857534Z",
     "iopub.status.idle": "2023-08-16T17:04:19.893305Z",
     "shell.execute_reply": "2023-08-16T17:04:19.892364Z"
    },
    "papermill": {
     "duration": 0.140723,
     "end_time": "2023-08-16T17:04:19.896372",
     "exception": false,
     "start_time": "2023-08-16T17:04:19.755649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 18\n",
    "num_epochs = 30\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.01\n",
    "model = SimpsonClassifier(num_classes)\n",
    "\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dataloader, dev_dataloader, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9640eb",
   "metadata": {
    "papermill": {
     "duration": 0.099063,
     "end_time": "2023-08-16T17:04:20.605011",
     "exception": false,
     "start_time": "2023-08-16T17:04:20.505948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Trial 2 - Figuring out Size :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2c1b367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:20.802792Z",
     "iopub.status.busy": "2023-08-16T17:04:20.802115Z",
     "iopub.status.idle": "2023-08-16T17:04:21.044175Z",
     "shell.execute_reply": "2023-08-16T17:04:21.042572Z"
    },
    "papermill": {
     "duration": 0.344472,
     "end_time": "2023-08-16T17:04:21.047051",
     "exception": false,
     "start_time": "2023-08-16T17:04:20.702579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpsonClassifier(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=80000, out_features=256, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpsonClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "                        \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*625,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model = SimpsonClassifier(18)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abd54d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:21.251739Z",
     "iopub.status.busy": "2023-08-16T17:04:21.250412Z",
     "iopub.status.idle": "2023-08-16T17:04:21.268148Z",
     "shell.execute_reply": "2023-08-16T17:04:21.266485Z"
    },
    "papermill": {
     "duration": 0.122992,
     "end_time": "2023-08-16T17:04:21.271349",
     "exception": false,
     "start_time": "2023-08-16T17:04:21.148357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72a04786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:21.704060Z",
     "iopub.status.busy": "2023-08-16T17:04:21.702995Z",
     "iopub.status.idle": "2023-08-16T17:04:21.718322Z",
     "shell.execute_reply": "2023-08-16T17:04:21.717358Z"
    },
    "papermill": {
     "duration": 0.119374,
     "end_time": "2023-08-16T17:04:21.720823",
     "exception": false,
     "start_time": "2023-08-16T17:04:21.601449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dev_dataloader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images.view(-1, 3, 200,200))\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_dataloader, 0):\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images.view(-1, 3, 200,200))\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_function(outputs, labels)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "#         # we want to save the model if the accuracy is the best\n",
    "#         if accuracy > best_accuracy:\n",
    "#             saveModel()\n",
    "#             best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cf6fa09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:04:21.925282Z",
     "iopub.status.busy": "2023-08-16T17:04:21.923469Z",
     "iopub.status.idle": "2023-08-16T17:04:21.931300Z",
     "shell.execute_reply": "2023-08-16T17:04:21.929515Z"
    },
    "papermill": {
     "duration": 0.112744,
     "end_time": "2023-08-16T17:04:21.934582",
     "exception": false,
     "start_time": "2023-08-16T17:04:21.821838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 391.985791,
   "end_time": "2023-08-16T17:04:24.557859",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-16T16:57:52.572068",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
